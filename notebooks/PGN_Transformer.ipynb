{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGN Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q_P2S0PswzKo"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1oqh0F6W3ad"
      },
      "source": [
        "# Treinando um modelo de linguagem Transformer do zero em partidas anotadas de xadrez\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-kkz81OY6xH"
      },
      "source": [
        "## 1. Treinando o *tokenizer*\n",
        "\n",
        "O vocabulário de escolha do presente notebook são as possíveis anotações de lances do formato PGN. Ao todo são mais de 14700 palavras que representam lances (ex: e4, Nf3, c5, d4xe5, e8=Q, etc.).\n",
        "\n",
        "Antes é preciso instalar as bibliotecas *transformers* e *tokenizers* da Huggingface.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5duRggBRZKvP"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daí montamos a pasta do Google Drive, que guardará os arquivos de treinamento do modelo e do tokenizer, além da nossa base de partidas."
      ],
      "metadata": {
        "id": "UbbnrGD1yDXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvqnwBoC3hjV",
        "outputId": "890a4c8b-00e4-4c5a-cff6-1ceb91c94d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para treinar o tokenizer, especificaremos o nosso vocabulário a partir de um arquivo que contém todos os tokens possíveis. Passaremos a lista consistindo desses tokens como tokens especiais e passeremos um caminho de arquivo qualquer com poucas anotações de partidas apenas para preencher o argumento de treino do tokenizer."
      ],
      "metadata": {
        "id": "IyANt6RfyWuT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnymRDLe0hi",
        "outputId": "92d0b3a2-8ed5-4135-e35e-ddf0e8239735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import Unigram\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks'\n",
        "paths = ['/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/MacKenzie.pgn_simplified.spgn',\n",
        "         '/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/twic1431g/twic1431.pgn_simplified.spgn']\n",
        "\n",
        "tokenizer = Tokenizer(Unigram())\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "with open(f'{base_dir}/complete_vocab.txt', 'r') as f:\n",
        "  vocab = f.read().split('\\n')\n",
        "\n",
        "vocab += [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
        "\n",
        "# tokenizer.train(files=paths, vocab_size=len(vocab), min_frequency=1, special_tokens=vocab)\n",
        "from tokenizers.trainers import UnigramTrainer\n",
        "trainer = UnigramTrainer(vocab_size=len(vocab), special_tokens=vocab)\n",
        "tokenizer.train(files=paths, trainer=trainer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/MacKenzie.pgn_simplified.spgn', '/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/twic1431g/twic1431.pgn_simplified.spgn']\n",
            "CPU times: user 927 ms, sys: 1 s, total: 1.93 s\n",
            "Wall time: 1.72 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo segue um exemplo de tokenização de uma entrada representando um começo de partida de xadrez."
      ],
      "metadata": {
        "id": "xdWYopN0zP7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.encode(\"e4 e5 Nf3 Nf6 d4 Nxe4 Bd3 d5 dxe5\")\n",
        "print(output.tokens)\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3J5Je9s2qGX",
        "outputId": "ee5178ed-a095-4fa3-ae4d-b5991126617a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['e4', 'e5', 'Nf3', 'Nf6', 'd4', 'Nxe4', 'Bd3', 'd5', 'dxe5']\n",
            "14731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ei7bqpRf1LH"
      },
      "source": [
        "Salvaremos o tokenizer no nosso diretório principal, especificado pela variável **model_dir**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIS-irI0f32P"
      },
      "source": [
        "model_dir = \"/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/pgnGPT\"\n",
        "tokenizer.model.save(model_dir)\n",
        "tokenizer.save(f\"{model_dir}/tokenizer.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKVWB8WShT-z"
      },
      "source": [
        "# # from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "# # from tokenizers.implementations import Tokenizer\n",
        "# from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "# # tokenizer = ByteLevelBPETokenizer(\n",
        "# #     \"./pgnBERT/vocab.json\",\n",
        "# #     \"./pgnBERT/merges.txt\",\n",
        "# # )\n",
        "# tokenizer = Tokenizer.from_file(\n",
        "#     f\"{model_dir}/tokenizer.json\"\n",
        "# )\n",
        "\n",
        "# # print(tokenizer.pad_token)\n",
        "# # tokenizer.mask_token = \"<mask>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO5M3vrAhcuj"
      },
      "source": [
        "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "#     (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "#     (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        "# )\n",
        "# tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Ye27nchfzq"
      },
      "source": [
        "# tokenizer.encode(\"e4 e5 Nf3 Nf6 d4\")\n",
        "# tokenizer.encode(\"e4 e5 Nf3 Nf6 d4\").tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQpUC_CDhnWW"
      },
      "source": [
        "## 2. Treinando o modelo de linguagem\n",
        "\n",
        "Poderemos treinar um *Masked Language Model* (MLM), tais como BERT e derivados, ou um *Causal Language Model* (CLM), tais como GPT. Pouca coisa muda quando usamos as bibliotecas da Huggingface.\n",
        "\n",
        "A seguir treinamos uma versão da arquitetura GPT-2 do zero.\n",
        "\n",
        "Primeiro, veremos se a GPU está disponível."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD140sFjh0LQ",
        "outputId": "6f2f1f1c-1cec-40f6-840f-08eeedb8daa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 25 01:28:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZZs-r6iKAV",
        "outputId": "9c0d094c-cd6b-4c4d-e115-212ea4213232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0qQzgrBi1OX"
      },
      "source": [
        "Agora definiremos a configuração do modelo. 15011 é o tamanho do vocabulário mais alguns tokens especiais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTXXutqeDzPi"
      },
      "source": [
        "# from transformers import RobertaConfig\n",
        "\n",
        "# RoBERTa:\n",
        "# config = RobertaConfig(\n",
        "#     vocab_size=15011,\n",
        "#     max_position_embeddings=514,\n",
        "#     num_attention_heads=12,\n",
        "#     num_hidden_layers=6,\n",
        "#     type_vocab_size=1,\n",
        "# )\n",
        "\n",
        "# GPT-2:\n",
        "from transformers import GPT2Model, GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "# Initializing a GPT2 configuration\n",
        "configuration = GPT2Config(\n",
        "    vocab_size=15011\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAwQ82JiE5pi"
      },
      "source": [
        "O tokenizer treinado e salvo anteriormente será carregado na forma de um GPT2TokenizerFast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4keFBUjQFOD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abd73a3-fe25-473e-f1cc-85343e155cec"
      },
      "source": [
        "# from transformers import RobertaTokenizerFast\n",
        "\n",
        "# RoBERTa:\n",
        "# tokenizer = RobertaTokenizerFast.from_pretrained(model_dir, max_len=512)\n",
        "\n",
        "# GPT-2:\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_dir, max_len=512)\n",
        "print(tokenizer.mask_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<mask>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Da primeira vez que o código é executado, o tokenizer ainda não possui alguns dos tokens especiais (BOS, EOS, PAD, UNK e MASK). Daí é preciso descomentar e executar a célula a seguir, que adiciona os novos tokens ao tokenizer."
      ],
      "metadata": {
        "id": "V56tyn0d93p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.bos_token = \"<s>\"\n",
        "# tokenizer.pad_token = \"<pad>\"\n",
        "# tokenizer.eos_token = \"</s>\"\n",
        "# tokenizer.unk_token = \"<unk>\"\n",
        "# tokenizer.mask_token = \"<mask>\"\n",
        "# tokenizer.save_pretrained(model_dir)"
      ],
      "metadata": {
        "id": "reK-s50lX5S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yNCw-3hFv9h"
      },
      "source": [
        "Agora inicializeremos o modelo.\n",
        "\n",
        "É importante destacar que não inicializaremos o modelo a partir de um treinado em linguagem natural, pois nosso objetivo é treinar nas partidas de xadrez em formato PGN.\n",
        "\n",
        "Na primeira execução, é preciso descomentar e executar a célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import RobertaForMaskedLM\n",
        "\n",
        "# Para RoBERTa:\n",
        "# model = RobertaForMaskedLM(config=config)\n",
        "\n",
        "# Para GPT-2:\n",
        "# model = GPT2LMHeadModel(config=configuration)"
      ],
      "metadata": {
        "id": "BAzda07E_A3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caso o modelo já tenha sido treinado e salvo, é possível carregá-lo:"
      ],
      "metadata": {
        "id": "lZyA8kDK_fkX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzMqR-dzF4Ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bea6a5-dd5f-4d6f-da63-60a962bbbe89"
      },
      "source": [
        "# from transformers import RobertaForMaskedLM\n",
        "\n",
        "# RoBERTa:\n",
        "# model = RobertaForMaskedLM.from_pretrained(\"/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/pgnBERT\")\n",
        "\n",
        "# GPT-2:\n",
        "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "\n",
        "print(model.num_parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97370880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBtUHRMliOLM"
      },
      "source": [
        "### Criando o Dataset de treino\n",
        "\n",
        "Precisaremos definir a nossa própria classe de dataset herdando da classe Dataset do PyTorch. Faremos isso por questões de escalabilidade, visto que usar um LineByLineTextDataset requer que um arquivo com todas as partidas seja carregado inteiro na memória.\n",
        "\n",
        "O nosso CustomTextDataset lê as partidas de uma forma diferente: todas as partidas são distribuídas em 2000 arquivos, de modo que em um dado momento apenas parte das partidas precisa estar na memória."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import PreTrainedTokenizer\n",
        "from typing import Dict\n",
        "from glob import glob\n",
        "from functools import lru_cache\n",
        "import os\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "  def __init__(self, tokenizer: PreTrainedTokenizer, dir_path: str, block_size: int):\n",
        "    if not os.path.isdir(dir_path):\n",
        "      raise ValueError(f\"Input dir path {dir_path} not found\")\n",
        "    self._tokenizer = tokenizer\n",
        "    self._block_size = block_size\n",
        "    file_paths = glob(dir_path + \"/*\")\n",
        "    self._dir_path = dir_path\n",
        "    self._shard_len = 1000\n",
        "    self._len = 0\n",
        "    for file_path in file_paths:\n",
        "      with open(file_path, encoding=\"utf-8\") as f:\n",
        "        self._len += sum(1 for line in f if len(line) > 2)\n",
        "    self._mem = {}\n",
        "    print(self._len)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._len\n",
        "\n",
        "  def __getitem__(self, i) -> Dict[str, torch.tensor]:\n",
        "    if i in self._mem:\n",
        "      return self._mem[i]\n",
        "\n",
        "    shard = i // self._shard_len\n",
        "    eg = i % self._shard_len\n",
        "    fname = f'{self._dir_path}/{shard}.cpgn'\n",
        "\n",
        "    lines = []\n",
        "    with open(fname, encoding=\"utf-8\") as f:\n",
        "      for idx, line in enumerate(f):\n",
        "        if len(line) > 2:\n",
        "          lines.append(line)\n",
        "\n",
        "    batch_encoding = self._tokenizer(lines, add_special_tokens=True, truncation=True, max_length=self._block_size)\n",
        "    examples = batch_encoding[\"input_ids\"]\n",
        "    examples = [{\"input_ids\": torch.tensor(e, dtype=torch.long)} for e in examples]\n",
        "\n",
        "    for idx in range(len(examples)):\n",
        "      self._mem[shard * self._shard_len + idx] = examples[idx]\n",
        "\n",
        "    return examples[eg]"
      ],
      "metadata": {
        "id": "7NnsVFKvtUcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlvP_A-THEEl",
        "outputId": "d484c05a-81b0-4594-b3db-0f65d5d9755f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# from transformers import LineByLineTextDataset\n",
        "\n",
        "# dataset = LineByLineTextDataset(\n",
        "#     tokenizer=tokenizer,\n",
        "#     file_path=\"/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/clean_joint_100.cpgn\",\n",
        "#     block_size=128,\n",
        "# )\n",
        "\n",
        "dataset = CustomTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    dir_path=\"/content/drive/MyDrive/Unicamp/IA 376L - 2022.1/notebooks/cpgn\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1820744\n",
            "CPU times: user 1.33 s, sys: 472 ms, total: 1.8 s\n",
            "Wall time: 18.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDLs73HcIHk5"
      },
      "source": [
        "O data collator será usado na criação de batches de treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTgWPa9Dipk2"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# RoBERTa:\n",
        "# data_collator = DataCollatorForLanguageModeling(\n",
        "#     tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        "# )\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri2BIQKqjfHm"
      },
      "source": [
        "Agora inicializaremos nosso objeto Trainer, que é responsável pelo treino do modelo. O objeto TrainingArguments é usado para especificar parâmetros do treino como diretório de saída, número de épocas, tamanho do batch e outros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpvnFFmZJD-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa4db77-7cb7-41a4-8edd-3e8fff1f8fb0"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_gpu_train_batch_size=32,\n",
        "    save_steps=2000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6sASa36Nf-N"
      },
      "source": [
        "Agora iniciaremos o treino propriamente dito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmaHZXzmkNtJ"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZkooHz1-_2h"
      },
      "source": [
        "Salvaremos o modelo no nosso diretório para que possa ser carregado e usado depois, tanto para continuar o treino quanto para fazer inferência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDNgPls7_l13"
      },
      "source": [
        "trainer.save_model(model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0caceCy_p1-"
      },
      "source": [
        "## 3. Checando o modelo treinado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIQJ8ND_AEhl"
      },
      "source": [
        "Quando usamos um CLM, a parte generativa (decoder) retorna a probabilidade de cada palavra no vocabulário dadas as palavras anteriores (prompt). A seguir usaremos os escores da saída do método **generate** para criar partidas baseadas em diferentes estratégias de amostragem. A mais simples delas é a *greedy*, onde cada novo token é gerado e concatenado aos últimos. Outra forma de amostrar sequências de tokens consiste em pegar os próximos *k* tokens com maior probabilidade conjunta (dados os anteriores). O caso onde *k = 1* equivale ao greedy.\n",
        "\n",
        "Primeiro instalaremos a biblioteca python-chess, que será útil para validar as saídas do modelo, de modo que apenas partidas válidas sejam geradas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/niklasf/python-chess.git\n",
        "!cd python-chess; git checkout 46b1b0a6a1a7feda89775fc861a9b15fb5581740\n",
        "!cd python-chess; pip install -e ."
      ],
      "metadata": {
        "id": "fjQeHWjAr5Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.pgn as pgn\n",
        "import chess.svg\n",
        "import io\n",
        "import random\n",
        "import numpy as np\n",
        "from copy import copy"
      ],
      "metadata": {
        "id": "crhuM5hJE0RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora definiremos alguns métodos auxiliares e métodos para as diferentes técnicas de amostragem citadas."
      ],
      "metadata": {
        "id": "TVIgcNfAFGRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_end = ['1-0', '0-1', '1/2-1/2']\n",
        "\n",
        "def is_legal(board, move):\n",
        "  try:\n",
        "    san_move = board.parse_san(move)\n",
        "  except ValueError as e:\n",
        "    return False\n",
        "  return san_move in board.legal_moves\n",
        "\n",
        "def gen_next_greedy(prompt, prob_mass=0.7, random_seed=0):\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  input_ids = input_ids.input_ids\n",
        "  input_ids = input_ids.to(model.device)\n",
        "  outputs = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=False,\n",
        "      max_length=len(input_ids[0]) + 1,\n",
        "      output_scores=True,\n",
        "      return_dict_in_generate=True,\n",
        "      pad_token_id=tokenizer.eos_token_id\n",
        "  )\n",
        "  scores = outputs.scores[0].detach().cpu().numpy()[0]\n",
        "  prob_scores = np.exp(scores) / sum(np.exp(scores))\n",
        "  next_ids = np.argsort(scores)\n",
        "  acc_prob = 0.0\n",
        "  top_ids = []\n",
        "  for idx in range(len(next_ids) - 1, -1, -1):\n",
        "    if acc_prob >= prob_mass:\n",
        "      break\n",
        "    acc_prob += prob_scores[next_ids[idx]]\n",
        "    top_ids.append(next_ids[idx])\n",
        "  top_scores = prob_scores[top_ids]\n",
        "  outputs = tokenizer.batch_decode(torch.tensor([top_ids], device=model.device))\n",
        "  outputs = outputs[0]\n",
        "  ans = {'tokens': outputs.split(' '), 'probabilities': top_scores}\n",
        "  return ans\n",
        "\n",
        "def generate_greedy(prompt):\n",
        "  board = chess.Board()\n",
        "  for move in prompt.split(' '):\n",
        "    board.push_san(move)\n",
        "  for _ in range(200):\n",
        "    moves = gen_next_greedy(prompt, prob_mass=0.7)\n",
        "    norm_probs = moves['probabilities'] / sum(moves['probabilities'])\n",
        "    new_moves = np.random.choice(\n",
        "        moves['tokens'],\n",
        "        size=len(moves['tokens']),\n",
        "        replace=False,\n",
        "        p=norm_probs\n",
        "    )\n",
        "    idx = 0\n",
        "    while idx < len(new_moves) and not is_legal(board, new_moves[idx]):\n",
        "      idx += 1\n",
        "    if idx == len(new_moves):\n",
        "      new_move = '1/2-1/2'\n",
        "      prompt += ' ' + new_move\n",
        "      break\n",
        "    new_move = new_moves[idx]\n",
        "    prompt += ' ' + new_move\n",
        "    board.push_san(new_move)\n",
        "  return prompt\n",
        "\n",
        "def generate_best_next(prompt, k=4, prob_mass=0.7):\n",
        "  moves = gen_next_greedy(prompt, prob_mass)\n",
        "  moves, probs = moves['tokens'], moves['probabilities']\n",
        "  board = chess.Board()\n",
        "  for move in prompt.split(' '):\n",
        "    if len(move) > 0:\n",
        "      board.push_san(move)\n",
        "  if k <= 1:\n",
        "    idx = 0\n",
        "    while idx < len(moves) and not is_legal(board, moves[idx]):\n",
        "      idx += 1\n",
        "    if idx < len(moves):\n",
        "      return np.log(probs[idx]), moves[idx]\n",
        "    else:\n",
        "      print(prompt)\n",
        "      print(moves)\n",
        "      print(probs)\n",
        "      input()\n",
        "      return float('-inf'), ''\n",
        "  max_score = float('-inf')\n",
        "  max_moves = None\n",
        "  for move, prob in zip(moves, probs):\n",
        "    if is_legal(board, move):\n",
        "      sub_score, sub_moves = generate_best_next(\n",
        "          prompt + ' ' + move,\n",
        "          k - 1,\n",
        "          prob_mass\n",
        "      )\n",
        "      curr_score = np.log(prob) + sub_score\n",
        "      if curr_score > max_score:\n",
        "        max_score = curr_score\n",
        "        if len(sub_moves) > 0:\n",
        "          max_moves = move + ' ' + sub_moves\n",
        "        else:\n",
        "          max_moves = move\n",
        "  if max_moves is None:\n",
        "    return float('-inf'), ''\n",
        "  return max_score, max_moves\n",
        "\n",
        "def generate_best(prompt):\n",
        "  pass"
      ],
      "metadata": {
        "id": "X53s9vxBi_lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente podemos gerar algumas partidas."
      ],
      "metadata": {
        "id": "vWTEdvmrFRND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = 'c4'\n",
        "num_moves = 25\n",
        "k = 12\n",
        "num_iter = num_moves // k\n",
        "for _ in range(num_iter):\n",
        "  new_moves = generate_best_next(start, k=k, prob_mass=0.3)[1]\n",
        "  print(new_moves)\n",
        "  start += ' ' + new_moves\n",
        "print(start)\n",
        "\n",
        "# print(generate_greedy(start))"
      ],
      "metadata": {
        "id": "S9Scn5hzxTX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "af6JCBwIFdLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'e4'\n",
        "board = chess.Board()\n",
        "board.push_san(prompt)\n",
        "board.__str__().replace('\\n', ' | ') + ' > '"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LKTBP5ZyXnYC",
        "outputId": "1fd970dc-3965-4cb7-a03f-af9b4e46a035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r n b q k b n r | p p p p p p p p | . . . . . . . . | . . . . . . . . | . . . . P . . . | . . . . . . . . | P P P P . P P P | R N B Q K B N R > '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(generate_game(first_move='b3', depth=1, max_moves=1))\n",
        "\n",
        "# depth = 1\n",
        "# moves = generate('e4', k=depth, how='greedy', random_seed=1)\n",
        "\n",
        "prompt = 'e4'\n",
        "board = chess.Board()\n",
        "board.push_san(prompt)\n",
        "for _ in range(40):\n",
        "  moves = gen_next_greedy(prompt, prob_mass=0.7)\n",
        "  norm_probs = moves['probabilities'] / sum(moves['probabilities'])\n",
        "  new_moves = np.random.choice(\n",
        "      moves['tokens'],\n",
        "      size=len(moves['tokens']),\n",
        "      replace=False,\n",
        "      p=norm_probs\n",
        "  )\n",
        "  idx = 0\n",
        "  while idx < len(new_moves) and not is_legal(board, new_moves[idx]):\n",
        "    idx += 1\n",
        "  if idx == len(new_moves):\n",
        "    new_move = '1/2-1/2'\n",
        "    prompt += ' ' + new_move\n",
        "    break\n",
        "  new_move = new_moves[idx]\n",
        "  prompt += ' ' + new_move\n",
        "  board.push_san(new_move)\n",
        "print(prompt)\n",
        "\n",
        "# print(moves)\n",
        "# for idx in range(2, 10):\n",
        "#   moves = generate(moves, k=idx*depth, how='beam')\n",
        "#   print(moves)"
      ],
      "metadata": {
        "id": "TzMPd_-1njxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código antigo de exploração"
      ],
      "metadata": {
        "id": "q_P2S0PswzKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, k=30, how='greedy', random_seed=0):\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "  # sample up to 30 tokens\n",
        "  torch.manual_seed(random_seed)\n",
        "  if how == 'greedy':\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=False,\n",
        "        max_length=k,\n",
        "        output_scores=True,\n",
        "        return_dict_in_generate=True\n",
        "    )\n",
        "    print(outputs)\n",
        "    print(outputs.scores[0][0])\n",
        "    print(outputs.sequences[0])\n",
        "    # print(outputs.scores[0][0, outputs.sequences[0, 0]])\n",
        "    print(outputs.scores[0][0, outputs.sequences[0, -1]])\n",
        "    print(max(outputs.scores[0][0]))\n",
        "    outputs = outputs.sequences\n",
        "    outputs = tokenizer.batch_decode(outputs)\n",
        "  elif how == 'beam':\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        num_beams=100,\n",
        "        do_sample=True,\n",
        "        max_length=k,\n",
        "        output_scores=True,\n",
        "        return_dict_in_generate=True\n",
        "    )\n",
        "    outputs = tokenizer.batch_decode(outputs)\n",
        "  else:\n",
        "    outputs = model.generate(input_ids, do_sample=True, max_length=k)\n",
        "    outputs = tokenizer.batch_decode(outputs) # , skip_special_tokens=True\n",
        "  outputs = outputs[0]\n",
        "  return outputs\n",
        "\n",
        "def generate_game(first_move='e4', depth=5, max_moves=30, how='beam'):\n",
        "  prompt = first_move\n",
        "  board = chess.Board()\n",
        "  board.push_san(first_move)\n",
        "  for _ in range(0, max_moves, depth):\n",
        "    moves = generate(prompt, k=len(prompt.split(' ')) + depth, how=how)\n",
        "    moves = moves[len(prompt):]\n",
        "    moves = moves.split(' ')\n",
        "    for move in moves:\n",
        "      if is_legal(board, move):\n",
        "        board.push_san(move)\n",
        "        prompt += ' ' + move\n",
        "      else:\n",
        "        break\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "Nn34TOx5wfTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltXgXyCbAJLY"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=model_dir,\n",
        "    tokenizer=model_dir,\n",
        "    top_k=8,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_next_k(board, position, k):\n",
        "  if k <= 0:\n",
        "    return 0, []\n",
        "  moves = fill_mask(' '.join(position) + ' <mask>')\n",
        "  # moves = fill_mask(' '.join(position))\n",
        "  print(moves)\n",
        "  moves = [move for move in moves if move['token_str'] not in game_end]\n",
        "  max_score = float('-inf')\n",
        "  max_seq = []\n",
        "  for move in moves:\n",
        "    if is_legal(board, move['token_str']):\n",
        "      board.push_san(move['token_str'])\n",
        "      position.append(move['token_str'])\n",
        "      score, subseq = sample_next_k(\n",
        "          board,\n",
        "          position,\n",
        "          k - 1\n",
        "      )\n",
        "      score += np.log(move['score'])\n",
        "      subseq.insert(0, move['token_str'])\n",
        "      board.pop()\n",
        "      position.pop()\n",
        "      if score > max_score:\n",
        "        max_score = score\n",
        "        max_seq = copy(subseq)\n",
        "  return max_score, max_seq"
      ],
      "metadata": {
        "id": "3IUG17wxNcJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board = chess.Board()\n",
        "game = []\n",
        "for move in game:\n",
        "    board.push_san(move)\n",
        "for i in range(20):\n",
        "  _, moves = sample_next_k(board, game, 4)\n",
        "  print(moves)\n",
        "  for move in moves:\n",
        "    game.append(move)\n",
        "    board.push_san(move)\n",
        "    if board.is_fivefold_repetition():\n",
        "      break\n",
        "print(' '.join(game))"
      ],
      "metadata": {
        "id": "QwRl6zWSyOsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIvgZ3S6AO0z"
      },
      "source": [
        "game = ['c4', 'e5']\n",
        "\n",
        "board = chess.Board()\n",
        "for move in game:\n",
        "  board.push_san(move)\n",
        "\n",
        "for i in range(200):\n",
        "  idx = 0\n",
        "  found = True\n",
        "  moves = fill_mask(' '.join(game) + ' <mask>')\n",
        "  moves = [move for move in moves if move['token_str'] not in game_end]\n",
        "  # if random.randint(0, 10) > 8:\n",
        "  #   random.shuffle(moves)\n",
        "  print(' '.join([move['token_str'] for move in moves]))\n",
        "  move = moves[idx]['token_str']\n",
        "  while not is_legal(board, move):\n",
        "    idx += 1\n",
        "    # moves = fill_mask(' '.join(game) + ' <mask>')\n",
        "    # print(moves)\n",
        "    # input()\n",
        "    if idx < len(moves):\n",
        "      move = moves[idx]['token_str']\n",
        "    else:\n",
        "      found = False\n",
        "      break\n",
        "  # print(idx, end=' ')\n",
        "  if found and is_legal(board, move):\n",
        "    # print(idx, move, board.parse_san(move) in board.legal_moves)\n",
        "    game.append(move)\n",
        "    board.push_san(move)\n",
        "    if board.is_fivefold_repetition():\n",
        "      break\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game_str = ''\n",
        "for idx, move in enumerate(game):\n",
        "  if idx % 2 == 0:\n",
        "    game_str += f'{idx // 2 + 1}. {move} '\n",
        "  else:\n",
        "    game_str += f'{move} '\n",
        "game_str += '  1/2-1/2'\n",
        "print(game_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhCoq48-DmUY",
        "outputId": "ecf0bc89-1aec-45ec-cbe1-c29318d72698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. c4 e5 2. e4 Nc6 3. Nf3 Nf6 4. d3 Bc5 5. Nbd2 O-O 6. g3 a6 7. Bg2 d6 8. O-O Re8 9. Re1 h6 10. h3 Ba7 11. a3 Bc5 12. Rb1 Ba7 13. b4 Ne7 14. Bb2 Ng6 15. Qc2 c6 16. d4 Qe7 17. d5 c5 18. b5 a5 19. a4 b6 20. Qb3 Bb7 21. Qc2 Bc8 22. Qb3 Bd7 23. Qc2 Bc8 24. Qb3 Bd7 25. Qc2 Bg4 26. Qb3 Bc8 27. Qc2 Bd7 28. Qb3 Bc8 29. Qc2 Bd7 30. Qb3 Bc8 31. Qc2 Bd7 32. Qb3 Bc8 33. Qc2 Bd7 34. Qb3 Bc8   1/2-1/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from cairosvg import svg2png\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "X9GnctjNQHP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gif(gif_fn, frames):\n",
        "  frames = sorted(frames, key=lambda x: int(x.split('_')[-1].split('.')[-2]))\n",
        "  frames = [Image.open(image) for image in frames]\n",
        "  frame_one = frames[0]\n",
        "  frame_one.save(\n",
        "      gif_fn,\n",
        "      format=\"GIF\",\n",
        "      append_images=frames,\n",
        "      save_all=True,\n",
        "      duration=1000,\n",
        "      loop=0\n",
        "  )"
      ],
      "metadata": {
        "id": "M9QN1HPLkGaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pgn = io.StringIO('1. e4 Nf6 2. Nf3 e6 3. d4 e5  1/2-1/2')\n",
        "# game_str = '1. e4 c5 2. c4 e6 3. Nf3 d5 4. e5 Nc6 5. d4 Nh6 6. Nbd2 Nf5 7. Bd3 Be7 8. O-O O-O 9. b3 Na5 10. Bb2 b6 11. a3 Bb7 12. Qe2 Rc8 13. Bb1 c4'\n",
        "pgn = io.StringIO(game_str)\n",
        "game = chess.pgn.read_game(pgn)\n",
        "board = game.board()"
      ],
      "metadata": {
        "id": "OaxxSRyAFSTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svg2png(bytestring=chess.svg.board(board), write_to=f'boards/board_0.png')\n",
        "# with open('boards/board_0.svg', 'w') as f:\n",
        "#     f.write(chess.svg.board(board))\n",
        "for idx, move in enumerate(game.mainline_moves()):\n",
        "    board.push(move)\n",
        "    # board_svg = chess.svg.board(board)\n",
        "    # svg2png(bytestring=board_svg, write_to=f'boards/board_{idx + 1}.png')\n",
        "    # with open(f'boards/board_{idx + 1}.svg', 'w') as f:\n",
        "    #   f.write(board_svg)"
      ],
      "metadata": {
        "id": "osQxDTUGGFtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "AzAexPPTHdot",
        "outputId": "22c5b651-229f-4def-ac31-afcdbca7efe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnn1r1k1/3bq1b1/pp1p1p1p/P1pPp1p1/NPP1P3/3B1N1P/3B1PP1/R2QR1K1 b - - 19 29')"
            ],
            "image/svg+xml": "<svg baseProfile=\"tiny\" height=\"390\" version=\"1.2\" viewBox=\"0 0 390 390\" width=\"390\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><desc><pre>r n n . r . k .\n. . . b q . b .\np p . p . p . p\nP . p P p . p .\nN P P . P . . .\n. . . B . N . P\n. . . B . P P .\nR . . Q R . K .</pre></desc><defs><g class=\"white pawn\" id=\"white-pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#000000; stroke:#000000;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /></g><g class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g class=\"black pawn\" id=\"black-pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#ececec; stroke:#ececec;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-linejoin=\"miter\" stroke-width=\"1\" /></g><g class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect fill=\"#212121\" height=\"390\" width=\"390\" x=\"0\" y=\"0\" /><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 0) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 375) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 0) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 375) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 0) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 375) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 0) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 375) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 0) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 375) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 0) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 375) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 0) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 375) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 0) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 375) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect class=\"square dark a1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"330\" /><rect class=\"square light b1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"330\" /><rect class=\"square dark c1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"330\" /><rect class=\"square light d1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"330\" /><rect class=\"square dark e1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"330\" /><rect class=\"square light f1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"330\" /><rect class=\"square dark g1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"330\" /><rect class=\"square light h1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"330\" /><rect class=\"square light a2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"285\" /><rect class=\"square dark b2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"285\" /><rect class=\"square light c2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"285\" /><rect class=\"square dark lastmove d2\" fill=\"#aaa23b\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"285\" /><rect class=\"square light e2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"285\" /><rect class=\"square dark f2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"285\" /><rect class=\"square light g2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"285\" /><rect class=\"square dark h2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"285\" /><rect class=\"square dark a3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"240\" /><rect class=\"square light b3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"240\" /><rect class=\"square dark lastmove c3\" fill=\"#aaa23b\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"240\" /><rect class=\"square light d3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"240\" /><rect class=\"square dark e3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"240\" /><rect class=\"square light f3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"240\" /><rect class=\"square dark g3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"240\" /><rect class=\"square light h3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"240\" /><rect class=\"square light a4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"195\" /><rect class=\"square dark b4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"195\" /><rect class=\"square light c4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"195\" /><rect class=\"square dark d4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"195\" /><rect class=\"square light e4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"195\" /><rect class=\"square dark f4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"195\" /><rect class=\"square light g4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"195\" /><rect class=\"square dark h4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"195\" /><rect class=\"square dark a5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"150\" /><rect class=\"square light b5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"150\" /><rect class=\"square dark c5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"150\" /><rect class=\"square light d5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"150\" /><rect class=\"square dark e5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"150\" /><rect class=\"square light f5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"150\" /><rect class=\"square dark g5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"150\" /><rect class=\"square light h5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"150\" /><rect class=\"square light a6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"105\" /><rect class=\"square dark b6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"105\" /><rect class=\"square light c6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"105\" /><rect class=\"square dark d6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"105\" /><rect class=\"square light e6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"105\" /><rect class=\"square dark f6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"105\" /><rect class=\"square light g6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"105\" /><rect class=\"square dark h6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"105\" /><rect class=\"square dark a7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"60\" /><rect class=\"square light b7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"60\" /><rect class=\"square dark c7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"60\" /><rect class=\"square light d7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"60\" /><rect class=\"square dark e7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"60\" /><rect class=\"square light f7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"60\" /><rect class=\"square dark g7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"60\" /><rect class=\"square light h7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"60\" /><rect class=\"square light a8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"15\" /><rect class=\"square dark b8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"15\" /><rect class=\"square light c8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"15\" /><rect class=\"square dark d8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"15\" /><rect class=\"square light e8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"15\" /><rect class=\"square dark f8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"15\" /><rect class=\"square light g8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"15\" /><rect class=\"square dark h8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"15\" /><use href=\"#white-rook\" transform=\"translate(15, 330)\" xlink:href=\"#white-rook\" /><use href=\"#white-queen\" transform=\"translate(150, 330)\" xlink:href=\"#white-queen\" /><use href=\"#white-rook\" transform=\"translate(195, 330)\" xlink:href=\"#white-rook\" /><use href=\"#white-king\" transform=\"translate(285, 330)\" xlink:href=\"#white-king\" /><use href=\"#white-bishop\" transform=\"translate(150, 285)\" xlink:href=\"#white-bishop\" /><use href=\"#white-pawn\" transform=\"translate(240, 285)\" xlink:href=\"#white-pawn\" /><use href=\"#white-pawn\" transform=\"translate(285, 285)\" xlink:href=\"#white-pawn\" /><use href=\"#white-bishop\" transform=\"translate(150, 240)\" xlink:href=\"#white-bishop\" /><use href=\"#white-knight\" transform=\"translate(240, 240)\" xlink:href=\"#white-knight\" /><use href=\"#white-pawn\" transform=\"translate(330, 240)\" xlink:href=\"#white-pawn\" /><use href=\"#white-knight\" transform=\"translate(15, 195)\" xlink:href=\"#white-knight\" /><use href=\"#white-pawn\" transform=\"translate(60, 195)\" xlink:href=\"#white-pawn\" /><use href=\"#white-pawn\" transform=\"translate(105, 195)\" xlink:href=\"#white-pawn\" /><use href=\"#white-pawn\" transform=\"translate(195, 195)\" xlink:href=\"#white-pawn\" /><use href=\"#white-pawn\" transform=\"translate(15, 150)\" xlink:href=\"#white-pawn\" /><use href=\"#black-pawn\" transform=\"translate(105, 150)\" xlink:href=\"#black-pawn\" /><use href=\"#white-pawn\" transform=\"translate(150, 150)\" xlink:href=\"#white-pawn\" /><use href=\"#black-pawn\" transform=\"translate(195, 150)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(285, 150)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(15, 105)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(60, 105)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(150, 105)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(240, 105)\" xlink:href=\"#black-pawn\" /><use href=\"#black-pawn\" transform=\"translate(330, 105)\" xlink:href=\"#black-pawn\" /><use href=\"#black-bishop\" transform=\"translate(150, 60)\" xlink:href=\"#black-bishop\" /><use href=\"#black-queen\" transform=\"translate(195, 60)\" xlink:href=\"#black-queen\" /><use href=\"#black-bishop\" transform=\"translate(285, 60)\" xlink:href=\"#black-bishop\" /><use href=\"#black-rook\" transform=\"translate(15, 15)\" xlink:href=\"#black-rook\" /><use href=\"#black-knight\" transform=\"translate(60, 15)\" xlink:href=\"#black-knight\" /><use href=\"#black-knight\" transform=\"translate(105, 15)\" xlink:href=\"#black-knight\" /><use href=\"#black-rook\" transform=\"translate(195, 15)\" xlink:href=\"#black-rook\" /><use href=\"#black-king\" transform=\"translate(285, 15)\" xlink:href=\"#black-king\" /></svg>"
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_gif('board.gif', glob(f'boards/*.png'))"
      ],
      "metadata": {
        "id": "XqHCeDaQkDbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cD8bV-iUiG74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0qCyyhNAWZi"
      },
      "source": [
        "Ok, simple syntax/grammar works. Let’s try a slightly more interesting prompt:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RsGaD1qAfLP"
      },
      "source": [
        "## 5. Share your model 🎉"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oESe8djApQw"
      },
      "source": [
        "Finally, when you have a nice model, please think about sharing it with the community:\n",
        "\n",
        "- upload your model using the CLI: `transformers-cli upload`\n",
        "- write a README.md model card and add it to the repository under `model_cards/`. Your model card should ideally include:\n",
        "    - a model description,\n",
        "    - training params (dataset, preprocessing, hyperparameters), \n",
        "    - evaluation results,\n",
        "    - intended uses & limitations\n",
        "    - whatever else is helpful! 🤓\n",
        "\n",
        "### **TADA!**\n",
        "\n",
        "➡️ Your model has a page on http://huggingface.co/models and everyone can load it using `AutoModel.from_pretrained(\"username/model_name\")`.\n",
        "\n",
        "[![tb](https://huggingface.co/blog/assets/01_how-to-train/model_page.png)](https://huggingface.co/julien-c/EsperBERTo-small)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw9ifsgqBI2o"
      },
      "source": [
        "If you want to take a look at models in different languages, check https://huggingface.co/models\n",
        "\n",
        "[![all models](https://huggingface.co/front/thumbnails/models.png)](https://huggingface.co/models)\n"
      ]
    }
  ]
}